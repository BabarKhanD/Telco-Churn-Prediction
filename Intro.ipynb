{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "a35eeb9f-df70-4ab1-a243-2d2025888eb0",
      "cell_type": "markdown",
      "source": "# Introduction to the JupyterLab and Jupyter Notebooks\n\nThis is a short introduction to two of the flagship tools created by [the Jupyter Community](https://jupyter.org).\n\n> **‚ö†Ô∏èExperimental!‚ö†Ô∏è**: This is an experimental interface provided by the [JupyterLite project](https://jupyterlite.readthedocs.io/en/latest/). It embeds an entire JupyterLab interface, with many popular packages for scientific computing, in your browser. There may be minor differences in behavior between JupyterLite and the JupyterLab you install locally. You may also encounter some bugs or unexpected behavior. To report any issues, or to get involved with the JupyterLite project, see [the JupyterLite repository](https://github.com/jupyterlite/jupyterlite/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc).\n\n## JupyterLab üß™\n\n**JupyterLab** is a next-generation web-based user interface for Project Jupyter. It enables you to work with documents and activities such as Jupyter notebooks, text editors, terminals, and custom components in a flexible, integrated, and extensible manner. It is the interface that you're looking at right now.\n\n**For an overview of the JupyterLab interface**, see the **JupyterLab Welcome Tour** on this page, by going to `Help -> Welcome Tour` and following the prompts.\n\n> **See Also**: For a more in-depth tour of JupyterLab with a full environment that runs in the cloud, see [the JupyterLab introduction on Binder](https://mybinder.org/v2/gh/jupyterlab/jupyterlab-demo/HEAD?urlpath=lab/tree/demo).\n\n## Jupyter Notebooks üìì\n\n**Jupyter Notebooks** are a community standard for communicating and performing interactive computing. They are a document that blends computations, outputs, explanatory text, mathematics, images, and rich media representations of objects.\n\nJupyterLab is one interface used to create and interact with Jupyter Notebooks.\n\n**For an overview of Jupyter Notebooks**, see the **JupyterLab Welcome Tour** on this page, by going to `Help -> Notebook Tour` and following the prompts.\n\n> **See Also**: For a more in-depth tour of Jupyter Notebooks and the Classic Jupyter Notebook interface, see [the Jupyter Notebook IPython tutorial on Binder](https://mybinder.org/v2/gh/ipython/ipython-in-depth/HEAD?urlpath=tree/binder/Index.ipynb).\n\n## An example: visualizing data in the notebook ‚ú®\n\nBelow is an example of a code cell. We'll visualize some simple data using two popular packages in Python. We'll use [NumPy](https://numpy.org/) to create some random data, and [Matplotlib](https://matplotlib.org) to visualize it.\n\nNote how the code and the results of running the code are bundled together.",
      "metadata": {}
    },
    {
      "id": "69e884b3-6a41-4790-b040-db18a366e216",
      "cell_type": "code",
      "source": "# %% [markdown]\n# # Telco Customer Churn Prediction\n# ### Problem Statement & Objective\n# **Business Problem**: Telecom companies lose 15-25% of customers annually to churn.  \n# **ML Objective**: Build a classifier to predict churn with >0.60 F1-score.  \n# **Success Metrics**:\n# - Accuracy > 80%  \n# - F1-score > 0.60  \n# - ROC AUC > 0.75\n\n# %% [markdown]\n# ---\n# ## 1. Dataset Loading\n# **Source**: [IBM Telco Dataset](https://github.com/IBM/telco-customer-churn-on-icp4d)  \n# **Format**: CSV (7,043 rows √ó 21 columns)  \n# **License**: MIT\n\n# %%\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, \n                           f1_score, \n                           confusion_matrix, \n                           classification_report,\n                           roc_auc_score,\n                           RocCurveDisplay)\n\n# Load data\ndf = pd.read_csv(\"Telco-Customer-Churn.csv\")\nprint(f\"Data shape: {df.shape}\")\ndisplay(df.head(3))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5acb57b1-5ec1-44ef-b840-2c8aa754fb74",
      "cell_type": "code",
      "source": "# ## 2. Data Preprocessing\n# **Key Steps**:\n# 1. Handle missing values in TotalCharges\n# 2. Convert categorical Churn to binary\n# 3. Split features into numeric/categorical\n\n# %%\n# Clean TotalCharges\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\ndf = df.dropna(subset=['TotalCharges'])\n\n# Convert target\ndf['Churn'] = df['Churn'].map({'Yes':1, 'No':0})\n\n# Feature lists\nnumeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\ncategorical_features = ['InternetService', 'Contract', 'PaymentMethod']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3543ebef-43a6-4db2-9099-58c6dffb8a57",
      "cell_type": "code",
      "source": "# ## 3. Model Development\n# **Pipeline Architecture**:\n# 1. Numeric: Impute ‚Üí Scale  \n# 2. Categorical: Impute ‚Üí OneHot  \n# 3. Classifier: Logistic Regression\n\n# %%\n# Preprocessing\nnumeric_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer([\n    ('num', numeric_transformer, numeric_features),\n    ('cat', categorical_transformer, categorical_features)])\n\n# Full pipeline\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(class_weight='balanced',\n                                   max_iter=1000,\n                                   solver='liblinear'))\n])\n\n# %% [markdown]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9e709922-8e9d-46bd-bfb0-48d1eee810fa",
      "cell_type": "code",
      "source": "# ## 4. Training & Evaluation\n# **Strategy**: 80/20 train-test split with stratified sampling\n\n# %%\n# Split data\nX = df[numeric_features + categorical_features]\ny = df['Churn']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Train\npipeline.fit(X_train, y_train)\n\n# Evaluate\ny_pred = pipeline.predict(X_test)\ny_proba = pipeline.predict_proba(X_test)[:,1]\n\n# %% [markdown]\n# ### Evaluation Metrics\n# %%\n# Classification Report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n\n# Confusion Matrix\nplt.figure(figsize=(6,4))\nsns.heatmap(confusion_matrix(y_test, y_pred), \n            annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Predicted No', 'Predicted Yes'],\n            yticklabels=['Actual No', 'Actual Yes'])\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# ROC Curve\nRocCurveDisplay.from_predictions(y_test, y_proba)\nplt.plot([0,1], [0,1], linestyle='--')\nplt.title(\"ROC Curve\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "12845166-01e8-4cb2-8b9b-2bac9064e461",
      "cell_type": "code",
      "source": "# ## 5. Insights & Deployment\n# **Key Findings**:\n# - Top 3 Predictive Features:\n#   1. Contract type (Month-to-month)\n#   2. Tenure length\n#   3. Fiber optic internet\n\n# %%\n# Save model\njoblib.dump(pipeline, 'churn_model.joblib')\n\n# Feature Importance\nencoder = pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['encoder']\ncat_features = encoder.get_feature_names_out(categorical_features)\nall_features = numeric_features + list(cat_features)\n\npd.Series(pipeline.named_steps['classifier'].coef_[0],\n          index=all_features).sort_values().plot(kind='barh')\nplt.title(\"Logistic Regression Coefficients\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b9670d85-ef29-4dfd-b4b5-e76d279c1f1a",
      "cell_type": "markdown",
      "source": "## Next steps üèÉ\n\nThis is just a short introduction to JupyterLab and Jupyter Notebooks. See below for some more ways to interact with tools in the Jupyter ecosystem, and its community.\n\n### Other notebooks in this demo\n\nHere are some other notebooks in this demo. Each of the items below corresponds to a file or folder in the **file browser to the left**.\n\n- [**`Lorenz.ipynb`**](Lorenz.ipynb) uses Python to demonstrate interactive visualizations and computations around the [Lorenz system](https://en.wikipedia.org/wiki/Lorenz_system). It shows off basic Python functionality, including more visualizations, data structures, and scientific computing libraries.\n- [**`r.ipynb`**](r.ipynb) demonstrates the R programming language for statistical computing and data analysis.\n- [**`cpp.ipynb`**](cpp.ipynb) demonstrates the C++ programming language for scientific computing and data analysis.\n- [**`sqlite.ipynb`**](sqlite.ipynb) demonstrates how an in-browser sqlite kernel to run your own SQL commands from the notebook. It uses the [jupyterlite/xeus-sqlite-kernel](https://github.com/jupyterlite/xeus-sqlite-kernel).\n\n### Other sources of information in Jupyter\n\n- **More on using JupyterLab**: See [the JupyterLab documentation](https://jupyterlab.readthedocs.io/en/stable/) for more thorough information about how to install and use JupyterLab.\n- **More interactive demos**: See [try.jupyter.org](https://try.jupyter.org) for more interactive demos with the Jupyter ecosystem.\n- **Learn more about Jupyter**: See [the Jupyter community documentation](https://docs.jupyter.org) to learn more about the project, its community and tools, and how to get involved.\n- **Join our discussions**: The [Jupyter Community Forum](https://discourse.jupyter.org) is a place where many in the Jupyter community ask questions, help one another, and discuss issues around interactive computing and our ecosystem.",
      "metadata": {}
    }
  ]
}